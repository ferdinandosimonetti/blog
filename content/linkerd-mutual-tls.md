Title: LinkerD with Automatic certificate rotation on Ubuntu 22.04
Author: Ferdinando Simonetti
Tags: Kubernetes, Linkerd, Cert-Manager, Step CLI, Ubuntu 22.04, nf_tables
Category: Kubernetes
Date: 2022-12-09

Here are my findings about LinkerD Service Mesh and its *mutual automatic TLS* feature that encrypts communications between meshed Pods without any modification needed to them.

We'll start from a slightly (ok, severely) outdated K8S cluster to test the appropriate update procedure, too.

This article is meant as a work-in-progress.

## References

- **[Automatic mTLS](https://linkerd.io/2.12/features/automatic-mtls/)**
- **[Rotating certificates](https://linkerd.io/2.12/tasks/automatically-rotating-control-plane-tls-credentials/)**
- **[Replacing expired certificates](https://linkerd.io/2.12/tasks/replacing_expired_certificates/)**
- **[Proxy-init IPtables modes](https://linkerd.io/2.12/features/nft/)**
- **[Cert-Manager](https://cert-manager.io/docs/installation/helm/)**
- **[Step certificate manager](https://smallstep.com/cli/)**

## Cert-Manager installation

```
[test0|default] ferdi@DESKTOP-NL6I2OD:~$ helm install \
  cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.10.1 \
  --set installCRDs=true
NAME: cert-manager
LAST DEPLOYED: Fri Dec  9 09:39:17 2022
NAMESPACE: cert-manager
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
cert-manager v1.10.1 has been deployed successfully!

In order to begin issuing certificates, you will need to set up a ClusterIssuer
or Issuer resource (for example, by creating a 'letsencrypt-staging' issuer).

More information on the different types of issuers and how to configure them
can be found in our documentation:

https://cert-manager.io/docs/configuration/

For information on how to configure cert-manager to automatically provision
Certificates for Ingress resources, take a look at the `ingress-shim`
documentation:

https://cert-manager.io/docs/usage/ingress/
```

## Root CA certificate

We need a (long lasting) top-level certificate to serve as an origin for our mTLS certificates, so we'll create one ourselves with the aid of **Step CLI**.

### Creation

```
[test0|default] ferdi@DESKTOP-NL6I2OD:~$ step certificate create root.linkerd.cluster.local ca.crt ca.key \
  --profile root-ca \
  --no-password \
  --insecure \
  --not-after=87600h
Your certificate has been saved in ca.crt.
Your private key has been saved in ca.key.
```

We're creating it with a 10-years validity, plenty of time to experiment!

### Loading it to K8S

```
[test0|default] ferdi@DESKTOP-NL6I2OD:~$ kubectl create namespace linkerd
namespace/linkerd created
[test0|default] ferdi@DESKTOP-NL6I2OD:~$ kubectl create secret tls \
    linkerd-trust-anchor \
    --cert=ca.crt \
    --key=ca.key \
    --namespace=linkerd
secret/linkerd-trust-anchor created
```

We have created the **linkerd** namespace in advance, to be able to instruct Linkerd's Helm Chart to use the new certificate.

### Hooking it up to Cert-Manager

We're going to need an Issuer resource, referencing our Secret

```
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: linkerd-trust-anchor
  namespace: linkerd
spec:
  ca:
    secretName: linkerd-trust-anchor
```

And a Certificate generated by this Issuer

```
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: linkerd-identity-issuer
  namespace: linkerd
spec:
  secretName: linkerd-identity-issuer
  duration: 48h
  renewBefore: 25h
  issuerRef:
    name: linkerd-trust-anchor
    kind: Issuer
  commonName: identity.linkerd.cluster.local
  dnsNames:
  - identity.linkerd.cluster.local
  isCA: true
  privateKey:
    algorithm: ECDSA
  usages:
  - cert sign
  - crl sign
  - server auth
  - client auth
```

After having applied these Custom Resources, the situation will be:

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubectl get secrets,issuers,certificates
NAME                             TYPE                                  DATA   AGE
secret/default-token-pbgcg       kubernetes.io/service-account-token   3      8m10s
secret/linkerd-identity-issuer   kubernetes.io/tls                     3      29s
secret/linkerd-trust-anchor      kubernetes.io/tls                     2      7m33s

NAME                                          READY   AGE
issuer.cert-manager.io/linkerd-trust-anchor   True    41s

NAME                                                  READY   SECRET                    AGE
certificate.cert-manager.io/linkerd-identity-issuer   True    linkerd-identity-issuer   29s
```

## LinkerD

First of all, we'll need the CRDs

### First installation

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ helm install linkerd-crds -n linkerd --create-namespace linkerd/linkerd-crds
NAME: linkerd-crds
LAST DEPLOYED: Fri Dec  9 10:08:26 2022
NAMESPACE: linkerd
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The linkerd-crds chart was successfully installed ðŸŽ‰

To complete the linkerd core installation, please now proceed to install the
linkerd-control-plane chart in the linkerd namespace.

Looking for more? Visit https://linkerd.io/2/getting-started/
```

Then LinkerD itself, within the already present Namespace

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ helm install linkerd-control-plane -n linkerd \
  --set-file identityTrustAnchorsPEM=ca.crt \
  --set identity.issuer.scheme=kubernetes.io/tls \
  linkerd/linkerd-control-plane
NAME: linkerd-control-plane
LAST DEPLOYED: Fri Dec  9 10:09:58 2022
NAMESPACE: linkerd
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The Linkerd control plane was successfully installed ðŸŽ‰

To help you manage your Linkerd service mesh you can install the Linkerd CLI by running:

  curl -sL https://run.linkerd.io/install | sh

Alternatively, you can download the CLI directly via the Linkerd releases page:

  https://github.com/linkerd/linkerd2/releases/

To make sure everything works as expected, run the following:

  linkerd check

The viz extension can be installed by running:

  helm install linkerd-viz linkerd/linkerd-viz

Looking for more? Visit https://linkerd.io/2/getting-started/
```

### Course correction

My single-host K8S test cluster is running on top of **Ubuntu 22.04**, using **Rancher (now SuSE) RKE1** Kubernetes distribution.

This simple fact lead me to this dire situation, after having installed the Helm Chart as shown above.

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubectl get po
NAME                                      READY   STATUS                  RESTARTS   AGE
linkerd-destination-54bc79696d-xcw7f      0/4     Init:CrashLoopBackOff   7          14m
linkerd-identity-76578bd5b9-68vrc         0/2     Init:CrashLoopBackOff   7          14m
linkerd-proxy-injector-746646f874-j45l4   0/2     Init:CrashLoopBackOff   7          14m
```

Let's check what's wrong with all of them!

```
test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubectl describe po linkerd-identity-76578bd5b9-68vrc|grep Message
      Message:   2-12-09T09:21:28Z" level=info msg="iptables-save v1.8.8 (legacy): Cannot initialize: Permission denied (you must be root)\n\n"
  Type     Reason     Age                   From               Message
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubectl describe po linkerd-destination-54bc79696d-xcw7f|grep Message
      Message:   2-12-09T09:21:15Z" level=info msg="iptables-save v1.8.8 (legacy): Cannot initialize: Permission denied (you must be root)\n\n"
  Type     Reason     Age                From               Message
```

[There's](https://github.com/linkerd/linkerd2/issues/7749) a reference to this error, at the thread's bottom there is a suggestion about an Helm Chart parameter that could save the day.

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ helm upgrade --install linkerd-control-plane -n linkerd \
  --set-file identityTrustAnchorsPEM=ca.crt \
  --set identity.issuer.scheme=kubernetes.io/tls \
  --set "proxyInit.iptablesMode=nft" \
  linkerd/linkerd-control-plane
Release "linkerd-control-plane" has been upgraded. Happy Helming!
NAME: linkerd-control-plane
LAST DEPLOYED: Fri Dec  9 10:33:13 2022
NAMESPACE: linkerd
STATUS: deployed
REVISION: 2
TEST SUITE: None
NOTES:
The Linkerd control plane was successfully installed ðŸŽ‰

To help you manage your Linkerd service mesh you can install the Linkerd CLI by running:

  curl -sL https://run.linkerd.io/install | sh

Alternatively, you can download the CLI directly via the Linkerd releases page:

  https://github.com/linkerd/linkerd2/releases/

To make sure everything works as expected, run the following:

  linkerd check

The viz extension can be installed by running:

  helm install linkerd-viz linkerd/linkerd-viz

Looking for more? Visit https://linkerd.io/2/getting-started/
```

Unfortunately, it didn'help a lot, below you'll find the relevant excerpt of **kubectl describe pod**

```
      Reason:    Error
      Message:   ave v1.8.8 (nf_tables): Could not fetch rule set generation id: Permission denied (you must be root)\n\n"
time="2022-12-09T09:43:09Z" level=error msg="aborting firewall configuration"
Error: exit status 4
```

### Serious troubleshooting here


Ok, let's check the default values of the Helm Chart to find out something that could help us.

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ helm show values linkerd/linkerd-control-plane > linkerd-values.yml
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$
```

Here's the relevant section:

```
# proxy-init configuration
proxyInit:
  # -- Variant of iptables that will be used to configure routing. Currently,
  # proxy-init can be run either in 'nft' or in 'legacy' mode. The mode will
  # control which utility binary will be called. The host must support
  # whichever mode will be used
  iptablesMode: "legacy"
  # -- Default set of inbound ports to skip via iptables
  # - Galera (4567,4568)
  ignoreInboundPorts: "4567,4568"
  # -- Default set of outbound ports to skip via iptables
  # - Galera (4567,4568)
  ignoreOutboundPorts: "4567,4568"
  # -- Comma-separated list of subnets in valid CIDR format that should be skipped by the proxy
  skipSubnets: ""
  # -- Log level for the proxy-init
  # @default -- info
  logLevel: ""
  # -- Log format (`plain` or `json`) for the proxy-init
  # @default -- plain
  logFormat: ""
  image:
    # -- Docker image for the proxy-init container
    name: cr.l5d.io/linkerd/proxy-init
    # -- Pull policy for the proxy-init container Docker image
    # @default -- imagePullPolicy
    pullPolicy: ""
    # -- Tag for the proxy-init container Docker image
    version: v2.0.0
  resources:
    cpu:
      # -- Maximum amount of CPU units that the proxy-init container can use
      limit: 100m
      # -- Amount of CPU units that the proxy-init container requests
      request: 100m
    memory:
      # -- Maximum amount of memory that the proxy-init container can use
      limit: 20Mi
      # -- Amount of memory that the proxy-init container requests
      request: 20Mi
    ephemeral-storage:
      # -- Maximum amount of ephemeral storage that the proxy-init container can use
      limit: ""
      # -- Amount of ephemeral storage that the proxy-init container requests
      request: ""
  closeWaitTimeoutSecs: 0
  # -- Allow overriding the runAsNonRoot behaviour (<https://github.com/linkerd/linkerd2/issues/7308>)
  runAsRoot: false
  # -- This value is used only if runAsRoot is false; otherwise runAsUser will be 0
  runAsUser: 65534
  xtMountPath:
    mountPath: /run
    name: linkerd-proxy-init-xtables-lock
```

Let's go with the plain old brute-force approach (running it as **root** user, in this case)/

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ helm upgrade --install linkerd-control-plane -n linkerd \
  --set-file identityTrustAnchorsPEM=ca.crt \
  --set identity.issuer.scheme=kubernetes.io/tls \
  --set "proxyInit.iptablesMode=nft" \
  --set "proxyInit.runAsRoot=true" \
  linkerd/linkerd-control-plane
Release "linkerd-control-plane" does not exist. Installing it now.
```

Aaand... we did it! Everything's running!

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubectl get po
NAME                                      READY   STATUS    RESTARTS   AGE
linkerd-destination-7f5857f549-xsdjf      4/4     Running   0          79s
linkerd-identity-b7d47f674-2mrsm          2/2     Running   0          79s
linkerd-proxy-injector-5c5f849755-4xrz7   2/2     Running   0          79s
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ 
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ 
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ linkerd check
Linkerd core checks
===================

kubernetes-api
--------------
âˆš can initialize the client
âˆš can query the Kubernetes API

kubernetes-version
------------------
âˆš is running the minimum Kubernetes API version
âˆš is running the minimum kubectl version

linkerd-existence
-----------------
âˆš 'linkerd-config' config map exists
âˆš heartbeat ServiceAccount exist
âˆš control plane replica sets are ready
âˆš no unschedulable pods
âˆš control plane pods are ready
âˆš cluster networks contains all node podCIDRs
âˆš cluster networks contains all pods
âˆš cluster networks contains all services

linkerd-config
--------------
âˆš control plane Namespace exists
âˆš control plane ClusterRoles exist
âˆš control plane ClusterRoleBindings exist
âˆš control plane ServiceAccounts exist
âˆš control plane CustomResourceDefinitions exist
âˆš control plane MutatingWebhookConfigurations exist
âˆš control plane ValidatingWebhookConfigurations exist
âˆš proxy-init container runs as root user if docker container runtime is used

linkerd-identity
----------------
âˆš certificate config is valid
âˆš trust anchors are using supported crypto algorithm
âˆš trust anchors are within their validity period
âˆš trust anchors are valid for at least 60 days
âˆš issuer cert is using supported crypto algorithm
âˆš issuer cert is within its validity period
â€¼ issuer cert is valid for at least 60 days
    issuer certificate will expire on 2022-12-11T09:04:05Z
    see https://linkerd.io/2.12/checks/#l5d-identity-issuer-cert-not-expiring-soon for hints
âˆš issuer cert is issued by the trust anchor

linkerd-webhooks-and-apisvc-tls
-------------------------------
âˆš proxy-injector webhook has valid cert
âˆš proxy-injector cert is valid for at least 60 days
âˆš sp-validator webhook has valid cert
âˆš sp-validator cert is valid for at least 60 days
âˆš policy-validator webhook has valid cert
âˆš policy-validator cert is valid for at least 60 days

linkerd-version
---------------
âˆš can determine the latest version
âˆš cli is up-to-date

control-plane-version
---------------------
âˆš can retrieve the control plane version
âˆš control plane is up-to-date
âˆš control plane and cli versions match

linkerd-control-plane-proxy
---------------------------
âˆš control plane proxies are healthy
âˆš control plane proxies are up-to-date
âˆš control plane proxies and cli versions match

Status check results are âˆš
```

### Experiments with LinkerD

#### Protocols

[Here](https://linkerd.io/2.12/features/protocol-detection/#configuring-protocol-detection) you'll find a detailed explanation of the proxying capabilities of LinkerD, I'm quoting some excerpt

> Linkerd is capable of proxying all TCP traffic, including TLS connections, WebSockets, and HTTP tunneling.

> In most cases, Linkerd can do this without configuration. To accomplish this, Linkerd performs protocol detection to determine whether traffic is HTTP or HTTP/2 (including gRPC). If Linkerd detects that a connection is HTTP or HTTP/2, Linkerd automatically provides HTTP-level metrics and routing.

> If Linkerd cannot determine that a connection is using HTTP or HTTP/2, Linkerd will proxy the connection as a plain TCP connection, applying mTLS and providing byte-level metrics as usual.

> (Note that HTTPS calls to or from meshed pods are treated as TCP, not as HTTP. Because the client initiates the TLS connection, Linkerd is not be able to decrypt the connection to observe the HTTP transactions.)

> Linkerd maintains a default list of opaque ports that corresponds to the standard ports used by protocols that interact poorly with protocol detection. As of the 2.12 release, that list is: 25 (SMTP), 587 (SMTP), 3306 (MySQL), 4444 (Galera), 5432 (Postgres), 6379 (Redis), 9300 (ElasticSearch), and 11211 (Memcache).

> The following table contains common protocols that may require additional configuration.

| Protocol          | Standard port(s)	     | In default list? | Notes |
| ----------------- | ---------------------- | ---------------- | ----- |
| SMTP	            | 25, 587	               | Yes	            |       |
| MySQL             | 3306                   | Yes              |       | 
| PostgreSQL        | 5432                   | Yes              |       |
| Redis             | 6379                   | Yes              |       |
| ElasticSearch	    | 9300                   | Yes              |       |
| Memcache          | 11211                  | Yes              |       |
| MySQL with Galera	| 3306, 4444, 4567, 4568 | Partially	      | Ports 4567 and 4568 are not in Linkerdâ€™s default set of opaque ports |

#### Testbed

Install the Emojivoto test app

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/emojivoto.yml \
  | kubectl apply -f -
namespace/emojivoto created
serviceaccount/emoji created
serviceaccount/voting created
serviceaccount/web created
service/emoji-svc created
service/voting-svc created
service/web-svc created
deployment.apps/emoji created
deployment.apps/vote-bot created
deployment.apps/voting created
deployment.apps/web created
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubie ns emojivoto
```

And inject the LinkerD proxy component on every Deployment found

```
[test0|linkerd] ferdi@DESKTOP-NL6I2OD:~$ kubie ns emojivoto
[test0|emojivoto] ferdi@DESKTOP-NL6I2OD:~$ kubectl get -n emojivoto deploy -o yaml \ \
  | linkerd inject - \
  | kubectl apply -f -

deployment "emoji" injected
deployment "vote-bot" injected
deployment "voting" injected
deployment "web" injected

deployment.apps/emoji configured
deployment.apps/vote-bot configured
deployment.apps/voting configured
deployment.apps/web configured
```

#### Visualization tool

Let's install Linkerd's Web interface

```
helm upgrade --install linkerd-viz \
  --namespace linkerd-viz \
  --create-namespace \
  linkerd/linkerd-viz
```

And use it to check if the traffic between the injected pods.

### Securing the traffic

- [Basics on restricting access](https://linkerd.io/2.12/tasks/restricting-access/)
- [Policies](https://linkerd.io/2.12/reference/authorization-policy/)
- [Linkerd with K8S Jobs](https://itnext.io/three-ways-to-use-linkerd-with-kubernetes-jobs-c12ccc6d4c7c)